{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e163bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f152e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "data = pd.read_csv(\"../../data/structured/carbon.csv\")\n",
    "# profile = ProfileReport(data, title=\"Carbon Emissions Data Profiling Report\", explorative=True)\n",
    "# profile.to_file('../../data/files/analysis.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc0b838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['TID', 'logger'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "070ce889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organizar_por_timestamp_context(df, col_timestamp='timestamp', col_context='context'):\n",
    "    \"\"\"\n",
    "    Ordena o DataFrame pelo timestamp crescente e depois pelo context.\n",
    "    \n",
    "    Parâmetros:\n",
    "        df: pandas.DataFrame\n",
    "        col_timestamp: nome da coluna de timestamp\n",
    "        col_context: nome da coluna de contexto\n",
    "    Retorna:\n",
    "        DataFrame ordenado\n",
    "    \"\"\"\n",
    "    # Garantir que a coluna de timestamp é datetime\n",
    "    df[col_timestamp] = pd.to_datetime(df[col_timestamp])\n",
    "    # Ordenar pelos dois campos\n",
    "    df_ordenado = df.sort_values(by=[col_context,col_timestamp], ascending=[True, True]).reset_index(drop=True)\n",
    "    return df_ordenado\n",
    "\n",
    "data = organizar_por_timestamp_context(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e49c25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "# data['mes'] = data['timestamp'].dt.month\n",
    "data['dia'] = data['timestamp'].dt.day\n",
    "data['hora'] = data['timestamp'].dt.hour\n",
    "data['minuto'] = data['timestamp'].dt.minute\n",
    "data['segundo'] = data['timestamp'].dt.second\n",
    "data.drop(columns=['timestamp'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0a2f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd744d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona mensagens únicas do nível ERROR\n",
    "mensagens_erro = data['message'][data['level'] == 'ERROR'].unique()\n",
    "\n",
    "# Salva cada mensagem em uma nova linha de um arquivo .txt\n",
    "with open(\"../../data/files/unique_error.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for mensagem in mensagens_erro:\n",
    "        f.write(str(mensagem) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4248342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filtrar_e_salvar_erros(\n",
    "    df, \n",
    "    coluna_msg='message', \n",
    "    coluna_nivel='level', \n",
    "    termo_excluir='#getNewJsonPayload',\n",
    "    nivel_erro='ERROR',\n",
    "    caminho_saida='unique_error.txt'\n",
    "):\n",
    "    # Remove linhas com o termo indesejado\n",
    "    dataM = df[~df[coluna_msg].str.contains(termo_excluir, na=False)].reset_index(drop=True)\n",
    "    \n",
    "    # Seleciona mensagens únicas do nível especificado\n",
    "    mensagens_erro = dataM[coluna_msg][dataM[coluna_nivel] == nivel_erro].unique()\n",
    "    \n",
    "    # Salva no arquivo txt\n",
    "    with open(caminho_saida, \"w\", encoding=\"utf-8\") as f:\n",
    "        for mensagem in mensagens_erro:\n",
    "            f.write(str(mensagem) + \"\\n\")\n",
    "    \n",
    "    return dataM.reset_index(drop=True)\n",
    "\n",
    "# Exemplo de uso:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataM = filtrar_e_salvar_erros(data, caminho_saida=\"../../data/files/unique_error1.txt\")\n",
    "dataCNHR = filtrar_e_salvar_erros(dataM,caminho_saida=\"../../data/files/unique_error2.txt\",termo_excluir='Could not handle request')\n",
    "dataDSAF = filtrar_e_salvar_erros(dataCNHR,caminho_saida=\"../../data/files/unique_error3.txt\",termo_excluir='Deployment of synapse artifact failed')\n",
    "dataFSNRT = filtrar_e_salvar_erros(dataDSAF,caminho_saida=\"../../data/files/unique_error4.txt\",termo_excluir='Failed to start new registry transaction')\n",
    "dataKMRKMAIT = filtrar_e_salvar_erros(dataFSNRT,caminho_saida=\"../../data/files/unique_error5.txt\",termo_excluir='Key Manager Resident Key Manager already initialized in tenant')\n",
    "dataKMRKMAIT = filtrar_e_salvar_erros(dataKMRKMAIT,caminho_saida=\"../../data/files/unique_error6.txt\",termo_excluir='HttpException occurred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d64e12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona mensagens únicas do nível ERROR\n",
    "mensagens_erro = data['message'][data['level'] == 'WARN'].unique()\n",
    "\n",
    "# Salva cada mensagem em uma nova linha de um arquivo .txt\n",
    "with open(\"../../data/files/unique_warn.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for mensagem in mensagens_erro:\n",
    "        f.write(str(mensagem) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76e3ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona mensagens únicas do nível ERROR\n",
    "mensagens_erro = data['message'][data['level'] == 'INFO'].unique()\n",
    "\n",
    "# Salva cada mensagem em uma nova linha de um arquivo .txt\n",
    "with open(\"../../data/files/unique_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for mensagem in mensagens_erro:\n",
    "        f.write(str(mensagem) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
